pdf_file,title,abstract,label
A_Bayesian_Data_Augmentation_Approach_for_Learning_Deep_Models_1.pdf,A Bayesian Data Augmentation Approach for,"Data augmentation is an essential part of the training process applied to deep
learningmodels. Themotivationisthatarobusttrainingprocessfordeeplearning
modelsdependsonlargeannotateddatasets,whichareexpensivetobeacquired,
storedandprocessed. Thereforeareasonablealternativeistobeabletoautomat-
ically generate new annotated training samples using a process known as data
augmentation. The dominant data augmentation approach in the field assumes
thatnewtrainingsamplescanbeobtainedviarandomgeometricorappearance
transformationsappliedtoannotatedtrainingsamples,butthisisastrongassump-
tionbecauseitisunclearifthisisareliablegenerativemodelforproducingnew
trainingsamples. Inthispaper,weprovideanovelBayesianformulationtodata
augmentation,wherenewannotatedtrainingpointsaretreatedasmissingvariables
andgeneratedbasedonthedistributionlearnedfromthetrainingset. Forlearning,
weintroduceatheoreticallysoundalgorithm—generalisedMonteCarloexpecta-
tionmaximisation,anddemonstrateonepossibleimplementationviaanextension
oftheGenerativeAdversarialNetwork(GAN).ClassificationresultsonMNIST,
CIFAR-10andCIFAR-100showthebetterperformanceofourproposedmethod
comparedtothecurrentdominantdataaugmentationapproachmentionedabove—
theresultsalsoshowthatourapproachproducesbetterclassificationresultsthan
similarGANmodels.",Machine Learning Theory
A_Disentangled_Recognition_and_Nonlinear_Dynamics_Model_for_Unsupervised_Learning_1.pdf,A Disentangled Recognition and Nonlinear Dynamics,"Thispapertakesasteptowardstemporalreasoninginadynamicallychangingvideo,
notinthepixelspacethatconstitutesitsframes,butinalatentspacethatdescribes
the non-linear dynamics of the objects in its world. We introduce the Kalman
variationalauto-encoder,aframeworkforunsupervisedlearningofsequentialdata
thatdisentanglestwolatentrepresentations: anobject’srepresentation, coming
fromarecognitionmodel,andalatentstatedescribingitsdynamics.Asaresult,the
evolutionoftheworldcanbeimaginedandmissingdataimputed,bothwithoutthe
needtogeneratehighdimensionalframesateachtimestep. Themodelistrained
end-to-endonvideosofavarietyofsimulatedphysicalsystems,andoutperforms
competingmethodsingenerativeandmissingdataimputationtasks.",Machine Learning Theory
A_General_Framework_for_Robust_Interactive_Learning_1.pdf,A General Framework for Robust Interactive,"Weproposeageneralframeworkforinteractivelylearningmodels,suchas(binary
ornon-binary)classifiers,orderings/rankingsofitems,orclusteringsofdatapoints.
OurframeworkisbasedonageneralizationofAngluin’sequivalencequerymodel
andLittlestone’sonlinelearningmodel: ineachiteration,thealgorithmproposesa
model,andtheusereitheracceptsitorrevealsaspecificmistakeintheproposal.
Thefeedbackiscorrectonlywithprobabilityp> 1 (andadversariallyincorrect
2
withprobability1−p),i.e.,thealgorithmmustbeabletolearninthepresenceof
arbitrarynoise. Thealgorithm’sgoalistolearnthegroundtruthmodelusingfew
iterations.
Ourgeneralframeworkisbasedonagraphrepresentationofthemodelsanduser
feedback. Tobeabletolearnefficiently, itissufficientthattherebeagraphG
whosenodesarethemodels,and(weighted)edgescapturetheuserfeedback,with
thepropertythatifs,s∗aretheproposedandtargetmodels,respectively,thenany
(correct)userfeedbacks(cid:48) mustlieonashortests-s∗ pathinG. Underthisone
assumption,thereisanaturalalgorithm,reminiscentoftheMultiplicativeWeights
Updatealgorithm,whichwillefficientlylearns∗eveninthepresenceofnoisein
theuser’sfeedback.
Fromthisgeneralresult,werederivewithbarelyanyextraeffortclassicresultson
learningofclassifiersandarecentresultoninteractiveclustering;inaddition,we
easilyobtainnewinteractivelearningalgorithmsforordering/ranking.",Applied AI in Healthcare & Web Systems
A_Greedy_Approach_for_Budgeted_Maximum_Inner_Product_Search_1.pdf,A Greedy Approach for,"Maximum Inner Product Search (MIPS) is an important task in many machine
learningapplicationssuchasthepredictionphaseoflow-rankmatrixfactorization
modelsanddeeplearningmodels. Recently,therehasbeensubstantialresearch
onhowtoperformMIPSinsub-lineartime,butmostoftheexistingworkdoes
not have the flexibility to control the trade-off between search efficiency and
search quality. In this paper, we study the important problem of MIPS with a
computationalbudget. BycarefullystudyingtheproblemstructureofMIPS,we
developanovelGreedy-MIPSalgorithm, whichcanhandlebudgetedMIPSby
design. While simple and intuitive, Greedy-MIPS yields surprisingly superior
performancecomparedtostate-of-the-artapproaches. Asaspecificexample,ona
candidatesetcontaininghalfamillionvectorsofdimension200,Greedy-MIPS
runs 200x faster than the naive approach while yielding search results with the
top-5precisiongreaterthan75%.",Machine Learning Theory
A_Meta-Learning_Perspective_on_Cold-Start_Recommendations_for_Items_1.pdf,A Meta-Learning Perspective on Cold-Start,"Matrixfactorization(MF)isoneofthemostpopulartechniquesforproductrecom-
mendation,butisknowntosufferfromseriouscold-startproblems. Itemcold-start
problemsareparticularlyacuteinsettingssuchasTweetrecommendationwhere
newitemsarrivecontinuously. Inthispaper,wepresentameta-learningstrategy
toaddressitemcold-startwhennewitemsarrivecontinuously. Weproposetwo
deepneuralnetworkarchitecturesthatimplementourmeta-learningstrategy. The
firstarchitecturelearnsalinearclassifierwhoseweightsaredeterminedbytheitem
history while the second architecture learns a neural network whose biases are
insteadadjusted. Weevaluateourtechniquesonthereal-worldproblemofTweet
recommendation. OnproductiondataatTwitter,wedemonstratethatourproposed
techniques significantly beat the MF baseline and also outperform production
modelsforTweetrecommendation.",Machine Learning Theory
A_Minimax_Optimal_Algorithm_for_Crowdsourcing_1.pdf,A Minimax Optimal Algorithm for Crowdsourcing,"Weconsidertheproblemofaccuratelyestimatingthereliabilityofworkersbased
onnoisylabelstheyprovide,whichisa fundamentalquestionin crowdsourcing.
We proposeanovellowerboundontheminimaxestimationerrorwhichapplies
toanyestimationprocedure. We furtherproposeTriangularEstimation(TE),an
algorithmforestimating thereliability ofworkers. TE haslow complexity,may
beimplementedinastreamingsettingwhenlabelsareprovidedbyworkersinreal
time, and doesnotrely onan iterative procedure. We provethatTE is minimax
optimalandmatchesourlowerbound.Weconcludebyassessingtheperformance
ofTEandotherstate-of-the-artalgorithmsonbothsyntheticandreal-worlddata.",Applied AI in Healthcare & Web Systems
A_multi-agent_reinforcement_learning_model_of_common-pool_resource_appropriation_1.pdf,A multi-agent reinforcement learning model of,"Humanityfacesnumerousproblemsofcommon-poolresourceappropriation. This
classofmulti-agentsocialdilemmaincludestheproblemsofensuringsustainable
use of fresh water, common fisheries, grazing pastures, and irrigation systems.
Abstractmodelsofcommon-poolresourceappropriationbasedonnon-cooperative
gametheorypredictthatself-interestedagentswillgenerallyfailtofindsocially
positiveequilibria—aphenomenoncalledthetragedyofthecommons. However,
inreality,humansocietiesaresometimesabletodiscoverandimplementstable
cooperativesolutions. Decadesofbehavioralgametheoryresearchhavesought
touncoveraspectsofhumanbehaviorthatmakethispossible. Mostofthatwork
wasbasedonlaboratoryexperimentswhereparticipantsonlymakeasinglechoice:
how much to appropriate. Recognizing the importance of spatial and temporal
resourcedynamics,arecenttrendhasbeentowardexperimentsinmorecomplex
real-time video game-like environments. However, standard methods of non-
cooperativegametheorycannolongerbeusedtogeneratepredictionsforthiscase.
Hereweshowthatdeepreinforcementlearningcanbeusedinstead. Tothatend,
westudytheemergentbehaviorofgroupsofindependentlylearningagentsina
partiallyobservedMarkovgamemodelingcommon-poolresourceappropriation.
Ourexperimentshighlighttheimportanceoftrial-and-errorlearningincommon-
poolresourceappropriationandshedlightontherelationshipbetweenexclusion,
sustainability,andinequality.",Applied AI in Healthcare & Web Systems
A_New_Theory_for_Matrix_Completion_1.pdf,A New Theory for Matrix Completion,"Prevalentmatrixcompletiontheoriesreplyonanassumptionthatthelocationsof
themissingdataaredistributeduniformlyandrandomly(i.e.,uniformsampling).
Nevertheless,thereasonforobservationsbeingmissingoftendependsontheunseen
observationsthemselves,andthusthemissingdatainpracticeusuallyoccursina
nonuniformanddeterministicfashionratherthanrandomly. Tobreakthroughthe
limitsofrandomsampling,thispaperintroducesanewhypothesiscalledisomeric
condition,whichisprovablyweakerthantheassumptionofuniformsamplingand
arguablyholdsevenwhenthemissingdataisplacedirregularly. Equippedwith
thisnewtool,weproveaseriesoftheoremsformissingdatarecoveryandmatrix
completion. Inparticular,weprovethattheexactsolutionsthatidentifythetarget
matrixareincludedascriticalpointsbythecommonlyusednonconvexprograms.
Unlike the existing theories for nonconvex matrix completion, which are built
uponthesameconditionasconvexprograms,ourtheoryshowsthatnonconvex
programshavethepotentialtoworkwithamuchweakercondition. Comparingto
theexistingstudiesonnonuniformsampling,oursetupismoregeneral.",Applied AI in Healthcare & Web Systems
Polynomial_time_algorithms_for_dual_volume_sampling_1.pdf,Polynomial time algorithms for dual volume sampling,"Westudydualvolumesampling,amethodforselectingkcolumnsfromann m
⇥
shortandwidematrix(n k m)suchthattheprobabilityofselectionispropor-
 
tionaltothevolumespannedbytherowsoftheinducedsubmatrix. Thismethod
wasproposedbyAvronandBoutsidis(2013),whoshowedittobeapromising
methodfor columnsubset selectionand its multipleapplications. However, its
wideradoptionhasbeenhamperedbythelackofpolynomialtimesamplingalgo-
rithms.Weremovethishindrancebydevelopinganexact(randomized)polynomial
time sampling algorithm as well as its derandomization. Thereafter, we study
dualvolumesamplingviathetheoryofrealstablepolynomialsandprovethatits
distribution satisfies the “Strong Rayleigh” property. This result has numerous
consequences,includingaprovablyfast-mixingMarkovchainsamplerthatmakes
dualvolumesamplingmuchmoreattractivetopractitioners.Thissamplerisclosely
relatedtoclassicalalgorithmsforpopularexperimentaldesignmethodsthatareto
datelackingtheoreticalanalysisbutareknowntoempiricallyworkwell.",Applied AI in Healthcare & Web Systems
Population_Matching_Discrepancy_and_Applications_in_Deep_Learning_1.pdf,Population Matching Discrepancy and,"A differentiable estimation of the distance between two distributions based on
samplesisimportantformanydeeplearningtasks. Onesuchestimationismaxi-
mummeandiscrepancy(MMD).However,MMDsuffersfromitssensitivekernel
bandwidthhyper-parameter,weakgradients,andlargemini-batchsizewhenused
asatrainingobjective. Inthispaper,weproposepopulationmatchingdiscrepancy
(PMD) for estimating the distribution distance based on samples, as well as an
algorithmtolearntheparametersofthedistributionsusingPMDasanobjective.
PMDisdefinedastheminimumweightmatchingofsamplepopulationsfromeach
distribution,andweprovethatPMDisastronglyconsistentestimatorofthefirst
Wassersteinmetric. WeapplyPMDtotwodeeplearningtasks,domainadaptation
andgenerativemodeling. EmpiricalresultsdemonstratethatPMDovercomesthe
aforementioneddrawbacksofMMD,andoutperformsMMDonbothtasksinterms
oftheperformanceaswellastheconvergencespeed.",Machine Learning Theory
Premise_Selection_for_Theorem_Proving_by_Deep_Graph_Embedding_1.pdf,Premise Selection for Theorem Proving,"Weproposeadeeplearning-basedapproachtotheproblemofpremiseselection:
selecting mathematical statements relevant for proving a given conjecture. We
represent a higher-order logic formula as a graph that is invariant to variable
renaming but still fully preserves syntactic and semantic information. We then
embedthegraphintoavectorviaanovelembeddingmethodthatpreservesthe
informationofedgeordering. Ourapproachachievesstate-of-the-artresultsonthe
HolStepdataset,improvingtheclassificationaccuracyfrom83%to90.3%.",Graph-Based Learning
_Exploration__A_Study_of_Count-Based_Exploration_for_Deep_Reinforcement_Learning_1.pdf,#Exploration: A Study of Count-Based Exploration,"Count-basedexplorationalgorithmsareknowntoperformnear-optimallywhen
usedinconjunctionwithtabularreinforcementlearning(RL)methodsforsolving
small discrete Markov decision processes (MDPs). It is generally thought that
count-basedmethodscannotbeappliedinhigh-dimensionalstatespaces, since
moststateswillonlyoccuronce. RecentdeepRLexplorationstrategiesareableto
dealwithhigh-dimensionalcontinuousstatespacesthroughcomplexheuristics,
often relying on optimism in the face of uncertainty or intrinsic motivation. In
thiswork,wedescribeasurprisingfinding: asimplegeneralizationoftheclassic
count-basedapproachcanreachnearstate-of-the-artperformanceonvarioushigh-
dimensionaland/orcontinuousdeepRLbenchmarks. Statesaremappedtohash
codes,whichallowstocounttheiroccurrenceswithahashtable. Thesecounts
are then used to compute a reward bonus according to the classic count-based
explorationtheory. Wefindthatsimplehashfunctionscanachievesurprisingly
good results on many challenging tasks. Furthermore, we show that a domain-
dependentlearnedhashcodemayfurtherimprovetheseresults. Detailedanalysis
revealsimportantaspectsofagoodhashfunction:1)havingappropriategranularity
and2)encodinginformationrelevanttosolvingtheMDP.Thisexplorationstrategy
achievesnearstate-of-the-artperformanceonbothcontinuouscontroltasksand
Atari 2600 games, hence providing a simple yet powerful baseline for solving
MDPsthatrequireconsiderableexploration.",Optimization Algorithms
