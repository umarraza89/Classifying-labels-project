pdf_file,title,abstract,label
Polynomial_time_algorithms_for_dual_volume_sampling_1.pdf,Polynomial time algorithms for dual volume sampling,"Westudydualvolumesampling,amethodforselectingkcolumnsfromann m
⇥
shortandwidematrix(n k m)suchthattheprobabilityofselectionispropor-
 
tionaltothevolumespannedbytherowsoftheinducedsubmatrix. Thismethod
wasproposedbyAvronandBoutsidis(2013),whoshowedittobeapromising
methodfor columnsubset selectionand its multipleapplications. However, its
wideradoptionhasbeenhamperedbythelackofpolynomialtimesamplingalgo-
rithms.Weremovethishindrancebydevelopinganexact(randomized)polynomial
time sampling algorithm as well as its derandomization. Thereafter, we study
dualvolumesamplingviathetheoryofrealstablepolynomialsandprovethatits
distribution satisfies the “Strong Rayleigh” property. This result has numerous
consequences,includingaprovablyfast-mixingMarkovchainsamplerthatmakes
dualvolumesamplingmuchmoreattractivetopractitioners.Thissamplerisclosely
relatedtoclassicalalgorithmsforpopularexperimentaldesignmethodsthatareto
datelackingtheoreticalanalysisbutareknowntoempiricallyworkwell.",Optimization Algorithms
Population_Matching_Discrepancy_and_Applications_in_Deep_Learning_1.pdf,Population Matching Discrepancy and,"A differentiable estimation of the distance between two distributions based on
samplesisimportantformanydeeplearningtasks. Onesuchestimationismaxi-
mummeandiscrepancy(MMD).However,MMDsuffersfromitssensitivekernel
bandwidthhyper-parameter,weakgradients,andlargemini-batchsizewhenused
asatrainingobjective. Inthispaper,weproposepopulationmatchingdiscrepancy
(PMD) for estimating the distribution distance based on samples, as well as an
algorithmtolearntheparametersofthedistributionsusingPMDasanobjective.
PMDisdefinedastheminimumweightmatchingofsamplepopulationsfromeach
distribution,andweprovethatPMDisastronglyconsistentestimatorofthefirst
Wassersteinmetric. WeapplyPMDtotwodeeplearningtasks,domainadaptation
andgenerativemodeling. EmpiricalresultsdemonstratethatPMDovercomesthe
aforementioneddrawbacksofMMD,andoutperformsMMDonbothtasksinterms
oftheperformanceaswellastheconvergencespeed.",Machine Learning Theory
Premise_Selection_for_Theorem_Proving_by_Deep_Graph_Embedding_1.pdf,Premise Selection for Theorem Proving,"Weproposeadeeplearning-basedapproachtotheproblemofpremiseselection:
selecting mathematical statements relevant for proving a given conjecture. We
represent a higher-order logic formula as a graph that is invariant to variable
renaming but still fully preserves syntactic and semantic information. We then
embedthegraphintoavectorviaanovelembeddingmethodthatpreservesthe
informationofedgeordering. Ourapproachachievesstate-of-the-artresultsonthe
HolStepdataset,improvingtheclassificationaccuracyfrom83%to90.3%.",Graph-Based Learning
